{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14e72afe-9128-4e8c-8503-6dd1af67c91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b24bbb95-8dc3-403e-883f-6ab12a7030a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "636da9f0-acb0-48ce-af71-edbc40fd226c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "from IConNet.signal import nextpow2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2c37a208-5598-4190-a259-0e0cb9864044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.parametrize as parametrize\n",
    "import math\n",
    "from einops import rearrange, reduce\n",
    "import opt_einsum as oe\n",
    "import numpy as np\n",
    "\n",
    "class LoremNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, downsample_factor=2,\n",
    "                 stride=1, padding=0, dilation=1, bias=False, groups=1,\n",
    "                 window_func='learnable', window_k: int=2):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        if kernel_size % 2 == 0: # Forcing the filters to be odd (i.e, perfectly symmetrics)\n",
    "            kernel_size += 1\n",
    "        self.kernel_size = kernel_size\n",
    "        self.out_channels = out_channels\n",
    "        self.learnable_params = nn.Parameter(torch.rand(window_k))\n",
    "        self.fir_filters = nn.Parameter(torch.rand(out_channels, in_channels, kernel_size))\n",
    "        self.window = nn.Parameter(torch.rand(self.kernel_size), requires_grad=False)\n",
    "        self.stride = stride\n",
    "        self.downsample_factor = downsample_factor\n",
    "\n",
    "    def forward(self, waveforms):\n",
    "        self.fir_filters = self.fir_filters.to(waveforms.device)\n",
    "        L = waveforms.shape[-1] // self.downsample_factor\n",
    "        return F.conv1d(waveforms, self.fir_filters, stride=self.stride)[..., :L]\n",
    "        \n",
    "\n",
    "class FIRWinFilters(nn.Module):\n",
    "    \"\"\"FIR filter design using the window method. (Ref: scipy.signal.firwin2)\n",
    "    Forward steps:\n",
    "        First, linearly interpolate the desired response on a uniform mesh `x`.\n",
    "        Then adjust the phases of the coefficients so that the first `ntaps` of the\n",
    "        inverse FFT are the desired filter coefficients.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_firwin_mesh(kernel_size, fs=2):\n",
    "        \"\"\"Frequency-domain mesh\"\"\"\n",
    "        nyq = fs/2\n",
    "        nfreqs = 1 + 2 ** nextpow2(kernel_size)\n",
    "        mesh_freq = torch.linspace(0.0, nyq, nfreqs) # (out_channels, in_channels, mesh_length) or (H C M)\n",
    "        shift_freq = torch.exp(-(kernel_size - 1) / 2. * 1.j * torch.pi * mesh_freq / nyq)\n",
    "        return mesh_freq, shift_freq\n",
    "    \n",
    "    def __init__(self, out_channels, in_channels, kernel_size, fs=2):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.fs = fs\n",
    "        mesh_freq, shift_freq = self.generate_firwin_mesh(kernel_size, fs)\n",
    "        self.register_buffer(\"mesh_freq\", mesh_freq)\n",
    "        self.register_buffer(\"shift_freq\", shift_freq)\n",
    "        \n",
    "        lowcut_bands = torch.rand(out_channels, in_channels)\n",
    "        bandwidths = torch.rand(out_channels, in_channels)\n",
    "        self.lowcut_bands = nn.Parameter(lowcut_bands)\n",
    "        self.bandwidths = nn.Parameter(bandwidths)\n",
    "    \n",
    "    def forward(self, W):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            W: (out_channels, in_channels, kernel_size) or (H C K). Time-domain windows.\n",
    "            bandwidths, lowcut_bands:  (out_channels, in_channels) or (H C)\n",
    "        Returns:\n",
    "            W: FIR filters\n",
    "        \"\"\"        \n",
    "        mesh1 = self.mesh_freq - self.lowcut_bands.abs()[..., None]\n",
    "        mesh2 = mesh1 - self.bandwidths.abs()[..., None]\n",
    "        x_freq = torch.logical_and(mesh1 >=0, mesh2 <= 0).float() # (H C M)\n",
    "        firwin_freq = oe.contract('hcm,m->hcm', x_freq, self.shift_freq) \n",
    "        firwin_time = torch.fft.irfft(firwin_freq)[..., :self.kernel_size] # (H C K)\n",
    "        W = firwin_time * W\n",
    "        return W\n",
    "\n",
    "    def right_inverse(self, W):\n",
    "        return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "635ac409-ce3f-4ce1-bd61-edec30478a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = LoremNet(2, 6, 16, 2, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "da3d5f17-bc06-487d-919f-46e61f4a391a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParametrizedLoremNet(\n",
       "  (parametrizations): ModuleDict(\n",
       "    (fir_filters): ParametrizationList(\n",
       "      (0): FIRWinFilters()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parametrize.register_parametrization(m, \"fir_filters\", FIRWinFilters(\n",
    "    out_channels=m.out_channels, in_channels=m.in_channels, kernel_size=m.kernel_size, fs=2\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e250ef85-713f-41fc-bf23-70a35d1f5a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.7017e-03, -3.5282e-02, -5.0047e-03,  8.5210e-03, -1.5822e-02,\n",
       "          -2.8166e-03,  1.7565e-02, -6.3762e-02,  1.9569e-01, -2.2612e-01,\n",
       "           1.3910e-01, -4.6428e-04, -1.4783e-02,  3.9140e-02, -3.8468e-03,\n",
       "          -3.1967e-02,  3.5957e-02],\n",
       "         [-8.0601e-03,  6.0330e-02, -2.5068e-02, -1.8187e-03, -2.1962e-02,\n",
       "           1.4407e-01, -3.4229e-02, -1.0448e-01,  1.0766e-01, -1.7890e-01,\n",
       "          -1.3118e-02,  2.1232e-02, -4.2757e-02, -2.1469e-05, -3.4763e-02,\n",
       "           8.9455e-02, -3.2677e-02]],\n",
       "\n",
       "        [[-1.1157e-02,  1.7915e-02, -5.9321e-03,  2.3713e-02, -2.8974e-03,\n",
       "          -2.6829e-03,  6.7615e-03, -1.5826e-02,  1.5835e-02, -7.8370e-03,\n",
       "           1.4101e-02, -2.7006e-03, -8.5758e-03,  9.8342e-03, -5.6956e-03,\n",
       "           1.3177e-02, -1.4380e-02],\n",
       "         [-3.7101e-02,  7.6319e-03,  7.7628e-03,  6.2964e-04, -7.7856e-02,\n",
       "           2.5357e-02,  2.2011e-02, -1.1627e-01,  4.8395e-02, -7.1270e-02,\n",
       "           7.3935e-03,  1.1059e-01, -8.7958e-02,  1.6055e-03,  1.0227e-02,\n",
       "           3.1893e-02, -3.9420e-02]],\n",
       "\n",
       "        [[ 2.2563e-02,  2.0721e-02, -3.1772e-02, -8.8217e-03,  3.0826e-02,\n",
       "           2.3400e-03, -2.9280e-02, -2.3120e-01,  1.5485e-01, -1.2370e-01,\n",
       "          -7.3926e-03,  1.8986e-02,  7.1813e-03, -2.7461e-02, -2.2004e-02,\n",
       "           1.9869e-02,  1.3410e-02],\n",
       "         [-7.0830e-02,  4.6822e-02, -4.5668e-02,  4.1332e-02, -8.8603e-03,\n",
       "          -2.2962e-02,  4.0893e-02, -9.4914e-02,  7.1813e-03, -2.2879e-02,\n",
       "           5.3940e-02, -1.6420e-02, -1.9911e-02,  2.1621e-02, -2.7518e-02,\n",
       "           8.3478e-02, -1.2265e-02]],\n",
       "\n",
       "        [[-1.8302e-02,  1.4450e-02,  4.8069e-03,  6.2989e-03,  5.2071e-02,\n",
       "          -2.5498e-02, -2.1824e-01,  1.1763e-02,  1.0042e-02,  3.7339e-03,\n",
       "          -1.7457e-01, -1.0020e-02,  1.2212e-01,  1.2921e-02,  6.7733e-03,\n",
       "           1.4551e-02, -9.7200e-03],\n",
       "         [ 8.6910e-09, -2.4759e-03, -4.9074e-03,  1.6910e-02,  1.6048e-08,\n",
       "           2.3707e-02, -1.5158e-01, -1.5255e-01,  4.4067e-03, -1.4687e-01,\n",
       "          -1.7980e-01,  1.0841e-01, -1.8789e-08,  6.4215e-02, -1.0244e-02,\n",
       "          -2.6989e-03, -7.1742e-10]],\n",
       "\n",
       "        [[-4.9396e-02, -1.5747e-02,  2.3140e-02,  3.0583e-02, -5.1109e-02,\n",
       "          -9.2808e-02,  1.6013e-02,  4.8467e-02,  4.0005e-01,  2.0209e-02,\n",
       "           1.6956e-02, -7.8122e-02, -2.7831e-02,  3.1331e-02,  1.5085e-02,\n",
       "          -1.8178e-02, -5.2322e-02],\n",
       "         [-1.2294e-02,  3.0901e-02, -4.0347e-03,  8.6368e-03,  1.4507e-02,\n",
       "          -2.6646e-02,  1.0092e-01, -2.0985e-01,  1.1602e-01, -5.3944e-02,\n",
       "           1.1936e-01, -2.8827e-02,  1.0686e-02,  2.3128e-02, -3.4052e-02,\n",
       "           3.0845e-02, -9.5543e-03]],\n",
       "\n",
       "        [[ 9.1444e-03,  3.6217e-03,  4.9171e-02,  4.9370e-03, -1.1522e-02,\n",
       "          -5.5913e-02, -1.4663e-01, -1.2090e-01,  1.1123e-01, -6.8862e-02,\n",
       "          -1.5574e-01, -7.2007e-03, -1.5364e-02,  2.0547e-02,  4.1056e-02,\n",
       "           3.4396e-03,  7.2407e-03],\n",
       "         [ 5.9383e-03, -1.9289e-04,  3.0708e-03, -1.3808e-02,  5.2848e-03,\n",
       "          -1.3690e-02,  1.6414e-03, -1.3207e-02,  1.3549e-02, -8.1407e-03,\n",
       "           1.3769e-02, -1.1786e-02,  1.0914e-02, -5.2259e-03,  4.0263e-03,\n",
       "          -5.7139e-03,  3.7756e-03]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fir_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a289c980-efab-4e12-8dc6-668107cba21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.4004, 0.0141], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.2773, 0.5896, 0.6565, 0.6562, 0.6065, 0.4650, 0.6236, 0.4431, 0.6235,\n",
       "         0.0043, 0.5421, 0.5090, 0.4531, 0.9472, 0.0734, 0.8139, 0.9858]),\n",
       " Parameter containing:\n",
       " tensor([[[0.0716, 0.9471, 0.9486, 0.1466, 0.2376, 0.5390, 0.1249, 0.2334,\n",
       "           0.5964, 0.8279, 0.9894, 0.0889, 0.2220, 0.6733, 0.7291, 0.8581,\n",
       "           0.9532],\n",
       "          [0.1511, 0.6737, 0.6607, 0.9928, 0.2671, 0.8146, 0.5751, 0.4341,\n",
       "           0.2650, 0.7433, 0.2204, 0.1201, 0.5200, 0.0117, 0.9162, 0.9990,\n",
       "           0.6125]],\n",
       " \n",
       "         [[0.5049, 0.5991, 0.1935, 0.9816, 0.2423, 0.8759, 0.3895, 0.5742,\n",
       "           0.5067, 0.2844, 0.8122, 0.8817, 0.7171, 0.4071, 0.1858, 0.4406,\n",
       "           0.6508],\n",
       "          [0.4918, 0.2314, 0.6491, 0.0293, 0.7008, 0.2038, 0.7624, 0.4435,\n",
       "           0.1291, 0.2718, 0.2561, 0.8888, 0.7918, 0.0746, 0.8551, 0.9672,\n",
       "           0.5225]],\n",
       " \n",
       "         [[0.5981, 0.8690, 0.7636, 0.1851, 0.6928, 0.0243, 0.6327, 0.7340,\n",
       "           0.2831, 0.3927, 0.1598, 0.1972, 0.1614, 0.5763, 0.5288, 0.8333,\n",
       "           0.3555],\n",
       "          [0.9388, 0.5153, 0.5206, 0.6488, 0.4010, 0.7987, 0.5283, 0.8450,\n",
       "           0.0575, 0.2037, 0.6969, 0.5711, 0.9011, 0.3394, 0.3137, 0.9187,\n",
       "           0.1626]],\n",
       " \n",
       "         [[0.3431, 0.4122, 0.5479, 0.2430, 0.4232, 0.4129, 0.7914, 0.3665,\n",
       "           0.0292, 0.1163, 0.6330, 0.1623, 0.9924, 0.4985, 0.7720, 0.4151,\n",
       "           0.1822],\n",
       "          [0.5146, 0.7693, 0.0517, 0.2315, 0.7880, 0.1623, 0.7494, 0.7923,\n",
       "           0.0088, 0.7628, 0.8890, 0.7421, 0.9226, 0.8791, 0.1079, 0.8386,\n",
       "           0.0760]],\n",
       " \n",
       "         [[0.9259, 0.3990, 0.8906, 0.9550, 0.8501, 0.8295, 0.5225, 0.1619,\n",
       "           0.9144, 0.0675, 0.5532, 0.6982, 0.4629, 0.9784, 0.5806, 0.4606,\n",
       "           0.9808],\n",
       "          [0.7868, 0.7370, 0.0783, 0.2612, 0.9284, 0.3115, 0.6362, 0.9813,\n",
       "           0.4950, 0.2523, 0.7524, 0.3370, 0.6839, 0.6996, 0.6611, 0.7357,\n",
       "           0.6115]],\n",
       " \n",
       "         [[0.5852, 0.0864, 0.9546, 0.1493, 0.7374, 0.6537, 0.9243, 0.5654,\n",
       "           0.1453, 0.3220, 0.9817, 0.0842, 0.9833, 0.6215, 0.7971, 0.0820,\n",
       "           0.4634],\n",
       "          [0.3801, 0.0123, 0.1965, 0.8837, 0.3382, 0.8761, 0.1051, 0.8452,\n",
       "           0.8672, 0.5210, 0.8812, 0.7543, 0.6985, 0.3345, 0.2577, 0.3657,\n",
       "           0.2416]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.6623, 0.5088],\n",
       "         [0.8362, 0.5685],\n",
       "         [0.4492, 0.8092],\n",
       "         [0.2946, 0.3957],\n",
       "         [0.0095, 0.7727],\n",
       "         [0.2413, 0.9756]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.5365, 0.4284],\n",
       "         [0.0181, 0.3830],\n",
       "         [0.7626, 0.1097],\n",
       "         [0.3463, 0.4920],\n",
       "         [0.4389, 0.7105],\n",
       "         [0.8893, 0.2368]], requires_grad=True)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = [p for p in m.parameters()]\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cdd7090a-319a-4b57-8711-37cbf2ffce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand(1, 2, 200)\n",
    "prediction = m(data)\n",
    "labels = torch.rand(1, 6, 100)\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(prediction, labels)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d3726452-82e7-4ff3-ad99-6d303010d58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 100])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d6375e44-27fc-4280-b46c-bd142a6a9559",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adamax(m.parameters(), lr=0.1)\n",
    "optim.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "47fffdf1-6ea8-4307-851d-cf79e9c1fdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand(50000, 2, 200)\n",
    "labels = torch.rand(50000, 6, 100)\n",
    "prediction = m(data)\n",
    "loss = criterion(prediction, labels)\n",
    "loss.backward()\n",
    "optim.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "84978130-2324-4e44-a8db-3389c872a7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3044, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "198e8f17-54bf-41d6-8ab2-45a4805af81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.4004, 0.0141], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2773, 0.5896, 0.6565, 0.6562, 0.6065, 0.4650, 0.6236, 0.4431, 0.6235,\n",
      "        0.0043, 0.5421, 0.5090, 0.4531, 0.9472, 0.0734, 0.8139, 0.9858])\n",
      "Parameter containing:\n",
      "tensor([[[ 0.0834, -0.0772, -0.0797,  0.0855, -0.0751, -0.0797,  0.0948,\n",
      "          -0.0636,  0.1253, -0.0642,  0.0949, -0.0795, -0.0749,  0.0858,\n",
      "          -0.0799, -0.0773,  0.0832],\n",
      "         [-0.0762,  0.0894, -0.0774, -0.0804, -0.0741,  0.0995, -0.0759,\n",
      "          -0.0654,  0.1430, -0.0654, -0.0758,  0.0995, -0.0737, -0.0804,\n",
      "          -0.0774,  0.0892, -0.0760]],\n",
      "\n",
      "        [[-0.0791,  0.0835, -0.0782,  0.0830, -0.0799, -0.0806,  0.0823,\n",
      "          -0.0787,  0.0835, -0.0787,  0.0826, -0.0808, -0.0795,  0.0828,\n",
      "          -0.0781,  0.0835, -0.0794],\n",
      "         [-0.0752,  0.0840,  0.0823,  0.0830, -0.0724,  0.0940,  0.0838,\n",
      "          -0.0647,  0.1348, -0.0645,  0.0834,  0.0936, -0.0725,  0.0834,\n",
      "           0.0826,  0.0842, -0.0753]],\n",
      "\n",
      "        [[ 0.0840,  0.0825, -0.0767, -0.0766,  0.0848,  0.0899, -0.0765,\n",
      "          -0.0639,  0.1930, -0.0629, -0.0771,  0.0901,  0.0850, -0.0766,\n",
      "          -0.0772,  0.0826,  0.0840],\n",
      "         [-0.0747,  0.0896, -0.0739,  0.0867, -0.0787, -0.0783,  0.0884,\n",
      "          -0.0723,  0.0937, -0.0720,  0.0882, -0.0782, -0.0790,  0.0870,\n",
      "          -0.0741,  0.0898, -0.0747]],\n",
      "\n",
      "        [[-0.0763,  0.0838,  0.0813,  0.0829,  0.0929, -0.0758, -0.0643,\n",
      "           0.0836,  0.1269,  0.0834, -0.0641, -0.0754,  0.0931,  0.0830,\n",
      "           0.0808,  0.0836, -0.0764],\n",
      "         [ 0.0314, -0.0807, -0.0735,  0.0878,  0.0359,  0.0960, -0.0670,\n",
      "          -0.0673,  0.1658, -0.0672, -0.0668,  0.0960, -0.0357,  0.0875,\n",
      "          -0.0735, -0.0803, -0.0214]],\n",
      "\n",
      "        [[-0.0751, -0.0757,  0.0818,  0.0821, -0.0745, -0.0709,  0.0823,\n",
      "           0.1171,  0.1599,  0.1171,  0.0821, -0.0712, -0.0743,  0.0820,\n",
      "           0.0815, -0.0756, -0.0747],\n",
      "         [-0.0785,  0.0833, -0.0755,  0.0823,  0.0808, -0.0728,  0.0966,\n",
      "          -0.0656,  0.1069, -0.0653,  0.0955, -0.0728,  0.0809,  0.0825,\n",
      "          -0.0753,  0.0834, -0.0784]],\n",
      "\n",
      "        [[ 0.0827,  0.0854,  0.0861,  0.0844, -0.0800, -0.0747, -0.0697,\n",
      "          -0.0671,  0.3147, -0.0670, -0.0700, -0.0747, -0.0804,  0.0843,\n",
      "           0.0861,  0.0857,  0.0826],\n",
      "         [ 0.0833, -0.0804,  0.0831, -0.0804,  0.0833, -0.0800,  0.0831,\n",
      "          -0.0804,  0.0831, -0.0804,  0.0834, -0.0805,  0.0833, -0.0807,\n",
      "           0.0831, -0.0807,  0.0829]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.6623, 0.5088],\n",
      "        [0.8362, 0.5685],\n",
      "        [0.4492, 0.8092],\n",
      "        [0.2946, 0.3957],\n",
      "        [0.0095, 0.7727],\n",
      "        [0.2413, 0.9756]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.5365, 0.4284],\n",
      "        [0.0181, 0.3830],\n",
      "        [0.7626, 0.1097],\n",
      "        [0.3463, 0.4920],\n",
      "        [0.4389, 0.7105],\n",
      "        [0.8893, 0.2368]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in m.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "4f8a886f-06ee-4b82-8155-bfc1175072b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7fb0b8ffbe80>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "a52c88f0-5c0f-41a0-8a58-ee7d4e747c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import repeat \n",
    "from IConNet.fftconv import fft_conv_complex2 as fft_conv\n",
    "\n",
    "class LoremNet2(nn.Module):\n",
    "    @staticmethod\n",
    "    def generate_firwin_mesh(kernel_size, fs=2):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            mesh_freq: (out_channels, in_channels, mesh_length) or (H C M).\n",
    "                Frequency-domain mesh.\n",
    "            shift_freq: (H C M). To adjust the phases of the coefficients so that the first\n",
    "                window coefficient of the inverse FFT are the desired filter coefficients.\n",
    "        \"\"\"\n",
    "        nyq = fs/2\n",
    "        nfreqs = 1 + 2 ** nextpow2(kernel_size)\n",
    "        mesh_freq = torch.linspace(0.0, nyq, nfreqs)\n",
    "        shift_freq = torch.exp(-(kernel_size - 1) / 2. * 1.j * torch.pi * mesh_freq / nyq)\n",
    "        return mesh_freq, shift_freq\n",
    "        \n",
    "    def __init__(self, in_channels, out_channels, kernel_size, \n",
    "                 fs=2, stride=1, padding=0, dilation=1, bias=False, groups=1,\n",
    "                 window_func='learnable', window_k: int=2):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        if kernel_size % 2 == 0: # Forcing the filters to be odd (i.e, perfectly symmetrics)\n",
    "            kernel_size += 1\n",
    "        self.kernel_size = kernel_size\n",
    "        self.out_channels = out_channels\n",
    "        self.window_k = window_k\n",
    "        self.window_params = nn.Parameter(torch.rand(window_k))\n",
    "        self.window = torch.rand(self.kernel_size, requires_grad=True)\n",
    "        self.stride = stride\n",
    "\n",
    "        self.fir_filters = torch.rand(out_channels, in_channels, kernel_size, \n",
    "                                      requires_grad=True)\n",
    "        self.fs = fs\n",
    "        self.mesh_freq, self.shift_freq = self.generate_firwin_mesh(kernel_size, fs)\n",
    "        \n",
    "        self.lowcut_bands = nn.Parameter(torch.rand(out_channels, in_channels))\n",
    "        self.bandwidths = nn.Parameter(torch.rand(out_channels, in_channels))\n",
    "\n",
    "    def forward(self, waveforms, trainable=True):\n",
    "        device = waveforms.device\n",
    "        \n",
    "        self.window_params = self.window_params.to(device)\n",
    "        self.lowcut_bands = self.lowcut_bands.to(device)\n",
    "        self.bandwidths = self.bandwidths.to(device)\n",
    "\n",
    "        # generate general cosine window from win_params\n",
    "        k = torch.linspace(0, 2*math.pi, self.kernel_size, \n",
    "                           requires_grad=trainable, device=device)\n",
    "        i = torch.arange(self.window_k, dtype=torch.float, device=device)[..., None]\n",
    "        self.window = (self.window_params[..., None] * (-1)**i * torch.cos(i * k)).sum(0).to(device)\n",
    "\n",
    "        # interpolate the desired filter coefficients in freq domain into the freq mesh\n",
    "        # example: mesh [0. .25 .5 .75 1.], low1=.1 low2=.6 => [0. 1. 1. 0. 0.]\n",
    "        self.fir_filters = repeat(self.window, 'k -> h c k', \n",
    "                                  h=self.out_channels, c=self.in_channels)\n",
    "        m = self.mesh_freq.shape[-1]\n",
    "        self.mesh1 = repeat(self.lowcut_bands, 'h c -> h c m', m=m)\n",
    "        self.mesh1 = self.mesh_freq - self.mesh1.abs()\n",
    "        self.mesh2 = self.mesh1 - self.bandwidths.abs()[..., None]\n",
    "\n",
    "        self.mesh1 = torch.clamp(torch.exp(self.mesh1), min=0., max=1.) # torch.where(mesh1 >= 0., 1., 0.)\n",
    "        self.mesh2 = torch.clamp(torch.exp(-self.mesh2), min=0., max=1.) # torch.where(mesh2 <= 0., 1., 0.)\n",
    "        self.x_freq = self.mesh1 * self.mesh2 #  torch.logical_and(mesh1, mesh2).float()\n",
    "        self.firwin_freq = oe.contract('hcm,m->hcm', self.x_freq, self.shift_freq) \n",
    "        \n",
    "        # bring the firwin to time domain & multiply with the time-domain window \n",
    "        self.firwin_time = torch.fft.irfft(self.firwin_freq)[..., :self.kernel_size] \n",
    "        self.fir_filters = oe.contract('hck,hck->hck', self.fir_filters, self.firwin_time)\n",
    "\n",
    "        # stride is downsampling factor \n",
    "        L = waveforms.shape[-1] // self.stride\n",
    "        p = self.stride - waveforms.shape[-1] % self.stride\n",
    "        padding = (0,p)\n",
    "        X = F.pad(waveforms, padding)\n",
    "        X = fft_conv(X, self.fir_filters, stride=self.stride)[..., :L]\n",
    "        return X\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "f9eb087f-1868-4834-ac97-84c15aeb6876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa = torch.tensor([1., 0., 1.], requires_grad=True)\n",
    "bbb = torch.tensor([1., 0., 1.], requires_grad=True)\n",
    "ccc = torch.logical_and(aaa, bbb, out=torch.empty(3, dtype=torch.float, requires_grad=True))\n",
    "ccc.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "a48167d5-000f-426b-b3d7-370a34526946",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = LoremNet2(2, 6, 16, 2, stride=2)\n",
    "criterion = nn.MSELoss()\n",
    "optim = torch.optim.Adamax(m2.parameters(), lr=0.1)\n",
    "optim.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "7df4fc21-050f-4f80-b9a6-5ecc8acd0e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.6944, 0.4354], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.0331, 0.1273],\n",
      "        [0.2398, 0.7785],\n",
      "        [0.8730, 0.1917],\n",
      "        [0.1795, 0.0370],\n",
      "        [0.4132, 0.6983],\n",
      "        [0.8793, 0.6502]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.8280, 0.9202],\n",
      "        [0.9723, 0.5889],\n",
      "        [0.4802, 0.7456],\n",
      "        [0.0258, 0.9927],\n",
      "        [0.2299, 0.1502],\n",
      "        [0.4180, 0.1721]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in m2.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "7258ffe4-a94f-4911-96fe-25056c5092a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand(1, 2, 200)\n",
    "labels = torch.rand(1, 6, 100)\n",
    "prediction = m2(data)\n",
    "loss = criterion(prediction, labels)\n",
    "loss.backward(retain_graph=True)\n",
    "optim.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "1bd7c30d-d5af-4bce-bb00-cba6bef66897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.7855, 4.0719])\n",
      "tensor([[-0.2930, -0.5516],\n",
      "        [-0.3282, -0.1903],\n",
      "        [-0.1880, -0.3239],\n",
      "        [-0.5459, -0.2780],\n",
      "        [-0.2405, -0.1816],\n",
      "        [-0.1251, -0.1470]])\n",
      "tensor([[-0.0004,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0038],\n",
      "        [ 0.0232,  0.0000],\n",
      "        [ 0.0091,  0.0005],\n",
      "        [ 0.0000,  0.0005]])\n"
     ]
    }
   ],
   "source": [
    "for p in m2.parameters():\n",
    "    print(p.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "1fc186eb-653e-4363-951e-11b2e76c7eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q_/ct58044n3cl5m_35j6c0mwfm0000gn/T/ipykernel_18437/1895866806.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1702400200181/work/build/aten/src/ATen/core/TensorBody.h:494.)\n",
      "  m2.firwin_time.grad\n"
     ]
    }
   ],
   "source": [
    "m2.firwin_time.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "1d55d6df-0469-47f9-8bd5-86df12c911dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.7855, 4.0719])"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.window_params.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "24e9aef6-be76-4745-acc7-8cdb588f7e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0004,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0038],\n",
       "        [ 0.0232,  0.0000],\n",
       "        [ 0.0091,  0.0005],\n",
       "        [ 0.0000,  0.0005]])"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.bandwidths.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "b458826d-acc8-44ed-a60a-a5622025a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand(10, 2, 200)\n",
    "labels = torch.rand(10, 6, 100)\n",
    "optim.zero_grad()\n",
    "prediction = m2(data)\n",
    "loss = criterion(prediction, labels)\n",
    "loss.backward(retain_graph=True)\n",
    "optim.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "2b7a913b-19fe-435c-b41e-2931d040c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand(50000, 2, 200)\n",
    "labels = torch.rand(50000, 6, 100)\n",
    "optim.zero_grad()\n",
    "prediction = m2(data)\n",
    "loss = criterion(prediction, labels)\n",
    "loss.backward(retain_graph=True)\n",
    "optim.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "c52a7016-5b23-4548-a2ba-05d32f3fae34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.3584, 1.4856])\n",
      "tensor([[-0.1640, -0.1588],\n",
      "        [-0.0712, -0.0446],\n",
      "        [-0.0411, -0.0742],\n",
      "        [-0.1408, -0.1572],\n",
      "        [-0.0503, -0.0416],\n",
      "        [-0.0209, -0.0256]])\n",
      "tensor([[ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0014],\n",
      "        [-0.0088,  0.0000],\n",
      "        [ 0.0036, -0.0009],\n",
      "        [ 0.0000, -0.0010]])\n"
     ]
    }
   ],
   "source": [
    "for p in m2.parameters():\n",
    "    print(p.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "c7ff6dcc-e319-46f9-9251-818fb9c9fe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand(50000, 2, 200)\n",
    "labels = torch.rand(50000, 6, 100)\n",
    "optim.zero_grad()\n",
    "prediction = m2(data)\n",
    "loss = criterion(prediction, labels)\n",
    "loss.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "8ea521e3-baa6-45ae-93a2-681ac42db0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7697, 0.8349])\n",
      "tensor([[-0.0833, -0.0822],\n",
      "        [-0.0294, -0.0199],\n",
      "        [-0.0176, -0.0298],\n",
      "        [-0.0702, -0.0800],\n",
      "        [-0.0184, -0.0166],\n",
      "        [-0.0052, -0.0063]])\n",
      "tensor([[ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0008],\n",
      "        [-0.0025,  0.0000],\n",
      "        [-0.0026, -0.0002],\n",
      "        [ 0.0000, -0.0005]])\n"
     ]
    }
   ],
   "source": [
    "for p in m2.parameters():\n",
    "    print(p.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "2e14eb94-7f66-4639-9abc-4a4cfcb89e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.4521, 0.1922], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.3120, 0.3629],\n",
      "        [0.4639, 1.0074],\n",
      "        [1.0975, 0.4201],\n",
      "        [0.4091, 0.3104],\n",
      "        [0.6367, 0.9284],\n",
      "        [1.0974, 0.8710]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.0054,  0.9202],\n",
      "        [ 0.9723,  0.5889],\n",
      "        [ 0.4802,  0.4959],\n",
      "        [-0.1246,  0.9927],\n",
      "        [-0.0145, -0.0414],\n",
      "        [ 0.4180, -0.0177]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in m2.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "ad0b7194-958d-4585-a8d8-e7a415c55b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.4013, 0.1410], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.3775, 0.4091],\n",
      "        [0.5042, 1.0497],\n",
      "        [1.1379, 0.4617],\n",
      "        [0.4526, 0.3736],\n",
      "        [0.6763, 0.9706],\n",
      "        [1.1337, 0.9083]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.0266,  0.9202],\n",
      "        [ 0.9723,  0.5889],\n",
      "        [ 0.4802,  0.4426],\n",
      "        [-0.1293,  0.9927],\n",
      "        [-0.0521, -0.0411],\n",
      "        [ 0.4180, -0.0176]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "data = torch.rand(50000, 2, 200)\n",
    "labels = torch.rand(50000, 6, 100)\n",
    "optim.zero_grad()\n",
    "prediction = m2(data)\n",
    "loss = criterion(prediction, labels)\n",
    "loss.backward(retain_graph=True)\n",
    "optim.step()\n",
    "for p in m2.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "090ee0c6-7e82-4129-8475-0d171149e4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.3604, 0.0998], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.4303, 0.4458],\n",
      "        [0.5353, 1.0825],\n",
      "        [1.1692, 0.4939],\n",
      "        [0.4870, 0.4245],\n",
      "        [0.7065, 1.0030],\n",
      "        [1.1608, 0.9361]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.0427,  0.9202],\n",
      "        [ 0.9723,  0.5889],\n",
      "        [ 0.4802,  0.3997],\n",
      "        [-0.1315,  0.9927],\n",
      "        [-0.0767, -0.0408],\n",
      "        [ 0.4180, -0.0183]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "data = torch.rand(50000, 2, 200)\n",
    "labels = torch.rand(50000, 6, 100)\n",
    "optim.zero_grad()\n",
    "prediction = m2(data)\n",
    "loss = criterion(prediction, labels)\n",
    "loss.backward(retain_graph=True)\n",
    "optim.step()\n",
    "for p in m2.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3aa395-b88f-4d69-bcf2-be2808163234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
